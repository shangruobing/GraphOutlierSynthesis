# 论文大纲

## 块

### 动机
图分布外数据检测通常缺少分布外数据样本，如果只有分布内数据，只能随机划分分布内数据作为异常值，通常不能准确描述分布外数据的特点。因此，一种以分布内数据为数据源，以最邻近距离的点的能量值为判断的合成方法被提出，用于解决分布外数据缺少时，提高模型分布外数据检测的能力。
### 目的
以原有分布内数据为基础，使用最邻近的距离的能量值，判断是否合适作为合成点，用这种新型的算法改进图分布外数据检测任务的效果。
### 方法
方法分为四步:


 1. **识别临界数据，探测分布边缘**

    图训练数据中最接近边界的一些数据，称之为临界数据。当收集足够的临界数据，可以分析出训练数据中的数据分布情况，探测到数据分布的边缘。**图训练数据中的边界是如何判断的呢？**

 2. **合成分布外数据**

    根据临界数据的分布，根据正态分布概率，合成新的数据，这些数据在临界数据周围，但是不属于原来训练集中的数据，这些数据称之为合成的分布外数据。**合成分布外的数据的详细步骤？**
    
 3. **能量过滤器**

    合成的分布外数据需要经过筛选，才能构建新的训练集投入模型训练。因此需要一个评估方法来鉴定合成数据的质量，能量函数是可以有效区分分布内数据和分布外数据，设置能量过滤器，将符合能量阈值的合成数据保留。

 4. **图能量网络训练**
    将合成的分布外数据作为少量异常值数据，与正常的训练集数据结合形成新的训练集。图神经网络采用能量函数作为损失函数，对新的训练集进行拟合，达到分布外数据识别的能力。


### 亮点
+ 处理分布外数据检测任务，不需要额外提供分布外数据
+ 对于分布外数据检测任务，有效提高分布外数据检测能力
+ 能与多种分布外数据检测任务方法相融合


### 同类方法
略

### 证明方法
略
## 条

### 摘要
### 背景
### 相关研究
### 问题定义
### 提出方法
在图训练任务中，每一次训练数据的输入，会在图网络上进行一次卷积操作，使得原有节点的值向着卷积中心的节点传播，而达到全图节点值更新的效果。


$$
Z^{(l)}=\sigma\left(D^{-1 / 2} \tilde{A} D^{-1 / 2} Z^{(l-1)} W^{(l)}\right), \quad Z^{(l-1)}=\left[\mathbf{z}_i^{(l-1)}\right]_{i \in \mathcal{I}}, \quad Z^{(0)}=X,
$$

其中$\tilde{A} $是自环邻接矩阵，$D$是对角度矩阵，$W^{(l)}$是权重矩阵，$\sigma$ 是一个非线性的激活函数，$l$是全网络卷积的次数（也可以看作是卷积层数）。

于是，图网络卷积过后的输出结果，等于是嵌入值，整个训练集可以表达为：


$$
\mathbb{Z}=\left({Z^{(l)}_1},{Z^{(l)}_1}, \dots {Z^{(l)}_n}\right)
$$


对于$\mathbb{Z}$任何嵌入值$Z$,可以计算它的距离

$$
d_k\left(\mathbf{Z^{\prime}}, \mathbb{Z}\right)=\left| {Z}^{\prime} - {Z}_{(k)} \right|_2
$$



### 实验
1. 获取GNN对ID数据的输出，得到监督学习loss。
2. 使用ID输出和OOD输出计算Energy ID和Energy OOD。
3. 如果使用能量传播，则进一步处理Energy ID和Energy OOD。
4. 计算正则化能量分数energy regularization loss
5. 使用ID和OOD训练分类器，使用Energy过滤合成的数据(可选)，得到分类器classifier loss

loss = 图监督学习supervised learning loss + 正则化能量分数energy regularization loss + 分类器classifier loss

loss = supervised learning loss + energy regularization loss + classifier loss


#### 数据集
数据集完全采用torch\_geometric提供的Planetoid, Amazon, Coauthor, Twitch, WikiCS, Actor, WebKB, GitHub等公开数据集。

#### 基线模型
"msp" "OE" "ODIN" "Mahalanobis" "maxlogits" "energymodel" "energyprop" "gnnsafe"

#### 编码器选择
"mlp" "sgc" "gcn" "gat" "mixhop" "gcnjk" "gatjk" "H2GCNConv" "APPNP_Net" "GPRPROP" "GPRGNN"

#### 评价指标
AUROC
AUPR
FPR
ACCURACY
SCORE

#### 消融实验
- loss中是否额外加入一个新的GCN分类器分数
- loss中是否加入能量正则化分数
- 是否使用能量分数来过滤分类器的输出
- 是否使用能量传播

排列组合
| 序号 | 使用能量   | 使用能量传播   | 使用分类器   | 过滤合成   |
| ---- | ---------- | -------------- | ------------ | ---------- |
| 1    | 不使用能量 |                |              |            |
| 2    | 使用能量   | 使用能量传播   | 使用分类器   | 过滤合成   |
| 3    | 使用能量   | 不使用能量传播 | 使用分类器   | 过滤合成   |
| 4    | 使用能量   | 使用能量传播   | 不使用分类器 | 过滤合成   |
| 5    | 使用能量   | 不使用能量传播 | 不使用分类器 | 过滤合成   |
| 6    | 使用能量   | 使用能量传播   | 使用分类器   | 不过滤合成 |
| 7    | 使用能量   | 不使用能量传播 | 使用分类器   | 不过滤合成 |
| 8    | 使用能量   | 使用能量传播   | 不使用分类器 | 不过滤合成 |
| 9    | 使用能量   | 不使用能量传播 | 不使用分类器 | 不过滤合成 |